{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from rdkit import Chem, DataStructs\n",
    "from rdkit.Chem import AllChem\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import r2_score\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout\n",
    "file=r\"C:\\Users\\VISWAM\\Downloads\\amf.csv\"\n",
    "db=pd.read_csv(file)\n",
    "#Converting SMILES to ECFP values \n",
    "def get_fingerprint(smiles,size=8192):\n",
    "  if ((smiles is None) or (pd.isnull(smiles))):\n",
    "    return np.zeros((size,))\n",
    "  molecule = Chem.MolFromSmiles(smiles)\n",
    "  if molecule is None:\n",
    "    return np.zeros((size,))\n",
    "  fingerprint = AllChem.GetMorganFingerprintAsBitVect(\n",
    "      molecule, 2, size)\n",
    "  arr = np.zeros((1,))\n",
    "  DataStructs.ConvertToNumpyArray(fingerprint, arr)\n",
    "  return arr \n",
    "cols=db.columns[[0,2,4,6,8,12]]\n",
    "col=db.columns[[1,3,5,7]]\n",
    "array=[]\n",
    "for a in cols:\n",
    "    j=[]\n",
    "    for i in range(0,len(db[a])):\n",
    "     temp=(get_fingerprint(db[a][i])).astype(int)\n",
    "     j.append(temp)\n",
    "    db[a]=j\n",
    "db.fillna(0,inplace=True)\n",
    "db2=pd.concat([pd.DataFrame(db[\"R\"].values.tolist()), pd.DataFrame(db[\"r1\"].values.tolist()),pd.DataFrame(db[\"r2\"].values.tolist()),pd.DataFrame(db[\"c1\"].values.tolist()),db['c1c'],pd.DataFrame(db[\"c2\"].values.tolist()),db['c2c'],pd.DataFrame(db[\"p\"].values.tolist()),db['t'],db['T'],db['m'],db['am'],db['l'],db['s']], axis=1)\n",
    "co=[\"c1c\",\"c2c\",\"t\",\"T\"]\n",
    "db2[co]=(db2[co]-db2[co].mean())/db2[co].std()\n",
    "db3=db['y']\n",
    "#splitting Dataset into train and test data\n",
    "xtr, xte, ytr, yte = train_test_split(db2, db3, test_size=0.1, random_state=35)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Regression model \n",
    "model = Sequential()\n",
    "reg = tf.keras.regularizers.l1_l2(l1=0.0001, l2=0.008)\n",
    "model.add(Dense(256 ,input_dim=xtr.shape[1], kernel_initializer='normal', kernel_regularizer=reg, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(384, kernel_initializer='normal', kernel_regularizer=reg, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(384, kernel_initializer='normal', kernel_regularizer=reg, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(512, kernel_initializer='normal', kernel_regularizer=reg, activation='relu'))\n",
    "model.add(Dropout(0.4))\n",
    "model.add(Dense(1,kernel_initializer='normal'))\n",
    "model.compile(loss='mean_squared_error', optimizer='adam', metrics=[r2_keras])\n",
    "model.summary()\n",
    "history= model.fit(xtr, ytr, validation_data=(xte, yte), epochs=100,verbose=2)\n",
    "# evaluation of the model\n",
    "# ploting loss during training\n",
    "plt.title('Loss')\n",
    "plt.plot(history.history['loss'], label='train')\n",
    "plt.plot(history.history['val_loss'], label='test')\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend()\n",
    "plt.savefig('regloss.png')\n",
    "plt.show()\n",
    "yp=model.predict(xte)\n",
    "ya=model.predict(xtr)\n",
    "# ploting predictions during training for test data\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(yte, yp)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "lims = [0, 100]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.plot(lims, lims)\n",
    "plt.savefig('testreg.png')\n",
    "plt.show()\n",
    "# ploting predictions during training for test data\n",
    "a = plt.axes(aspect='equal')\n",
    "plt.scatter(ytr, ya)\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "lims = [0, 100]\n",
    "plt.xlim(lims)\n",
    "plt.ylim(lims)\n",
    "plt.plot(lims, lims, color='red')\n",
    "plt.savefig('trainreg.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MAE of testing dataset\n",
    "y=yte.values.reshape((75,1))\n",
    "print(\"R2 Score=\",r2_score(yte,yp))\n",
    "er=np.abs(yp-y)\n",
    "print(er.mean(),er.std(),er.T)\n",
    "#MAE of training dataset\n",
    "ys=ytr.values.reshape((672,1))\n",
    "print(\"R2 Score=\",r2_score(ytr,ya))\n",
    "err=np.abs(ya-ys)\n",
    "print(err.mean(),err.std(),er.T)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
